{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOCATv2 FluxEngine Calculations\n",
    "\n",
    "Here we calculate air-sea flux using adapted code from FluxEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reanalysis CO2 data to a constant temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script function v2_f_confersion.py has been identified as the script that runs the fCO2 conversion\n",
    "As we don't wish to grid our observations, and we have matched SST and WS data from satelites prior, we will feed our array directly into this funtion to reanalyse CO2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard + 3rd Party libs\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions\n",
    "import datetime\n",
    "import argparse\n",
    "import netCDF4\n",
    "import glob\n",
    "import multiprocessing\n",
    "import pandas as pd;\n",
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\\\fluxengine_src\\\\tools\\\\reanalyse_socat\"))\n",
    "#Internal tool libs\n",
    "import get_sst\n",
    "import datenum\n",
    "import v2_f_conversion\n",
    "import netcdf_helper\n",
    "import combine_nc_files\n",
    "from pandas import DataFrame\n",
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\SOCATv2\\\\tools\"))\n",
    "import required_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up data frame for reanalysis using required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expocode', 'year', 'month', 'day', 'hour', 'minute', 'second', 'longitude', 'latitude', 'salinity', 'sst', 'T_equ', 'air_pressure', 'air_pressure_equ', 'salinity_sub', 'air_pressure_sub', 'fCO2', 'fCO2_qc_flag']\n",
      "Reading in data from SOCAT file: SOCATv2_SO_sst_ice_31012020.tsv\n",
      "This can take a while for large datasets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\SOCATv2\"))\n",
    "SOCAT_file = 'SOCATv2_SO_sst_ice_31012020.tsv'\n",
    "\n",
    "columnInfo = required_f.construct_column_info(year_col = 'yr', month_col = 'mon', day_col = 'day', hour_col = 'hh', minute_col = 'mm', second_col = 'ss', longitude_col = 'lon', latitude_col = 'lat', \\\n",
    "                                   salinity_col = 'sal', salinity_sub_col = 'WOA_SSS', SST_C_col = 'SST [deg.C]', Tequ_col = 'Tequ [deg.C]', air_pressure_col = 'PPPP [hPa]',  air_pressure_sub_col= 'NCEP_SLP [hPa]', air_pressure_equ_col= 'Pequ [hPa]', \\\n",
    "                                   fCO2_col= 'fCO2rec [uatm]', expocode_col = 'Expocode', socatversion = 6, notsocatformat = False);\n",
    "\n",
    "data=required_f.ReadInData(inputfile=SOCAT_file,columnInfo=columnInfo, socatversion=6)\n",
    "\n",
    "data_subset = data\n",
    "\n",
    "data_subset=data_subset[np.where(np.isfinite(data_subset['fCO2']))]\n",
    "#data_subset['longitude']=np.where(data_subset['longitude']>=180,\n",
    "#                                            data_subset['longitude']-360,data_subset['longitude'])\n",
    "#Finally we can remove columns which were only required for quality checks\n",
    "#these are days,hours,mins,fCO2rec_flag\n",
    "names=list(data_subset.dtype.names)\n",
    "[names.remove(x) for x in ['fCO2_qc_flag']] #'day','mm','hh','ss',\n",
    "names = [str(x) for x in names]; #Unicode strings can't be used to index, but are returned as column names. Weird.\n",
    "data_subset=data_subset[names]\n",
    "\n",
    "#Optionally update names to be more sensible - could do this at data import instead\n",
    "#Note this ASSUMES the order of the column naming - FIXME: should do this more robustly #TMH: Fixed: Order is now determined by the columnInfo object after parsing command line args.\n",
    "#newnames=['yr','mon','day','hh','mm','ss','lon','lat','sal','SST_C','Teq_C','P','Peq','sal_woa','P_ncep','fCO2_rec','expocode']\n",
    "newnames=[\"expocode\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"longitude\", \"latitude\", \"salinity\", \"sst\", \"T_equ\", \"air_pressure\", \"air_pressure_equ\", \"salinity_sub\", \"air_pressure_sub\", \"fCO2\"];\n",
    "data_subset.dtype.names=newnames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare jds, Tcls and Peq_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\SOCATv2\"))\n",
    "SOCAT_file2 = 'SOCATv2_SO_sst_ice_31012020.tsv'\n",
    "df = pd.read_table(SOCAT_file2, sep=\"\\t\")\n",
    "df_subset=df[np.isfinite(df['fCO2rec [uatm]'])]\n",
    "#df_subset['lon']=np.where(df_subset['lon']>=180,\n",
    "#                                            df_subset['lon']-360,df_subset['lon'])\n",
    "jds = datenum.datenum_array(data_subset['year'], data_subset['month'], data_subset['day'], data_subset['hour'], data_subset['minute'], 0)\n",
    "# no need to apply the subskin to skin estimate (note this is done in the v2_f_convert_f_SSH.py script in fluxengine) ast OISST is already subskin\n",
    "Tcls = np.array(df_subset['sst'] + 273.15,'<f8')\n",
    "#Tcls = Tcls.astype('<f8')\n",
    "Peq_cls = data_subset['air_pressure_sub'] + 3.\n",
    "#extrapolatetoyear = # we dont want to extrapolate to year... we are just interested in fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run reanalysis function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ignored points to temp file: c:\\users\\kabaldry\\appdata\\local\\temp\\ignore_points_6wveua\\ignored_points_8qwbyv\n"
     ]
    }
   ],
   "source": [
    "conversion = v2_f_conversion.v2_f_conversion_wrap(jds,data_subset,Tcls,Peq_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append to original data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_subset['SST_C'] =np.array(np.nan, '<f8')\n",
    "df_subset['SST_C'][conversion['goodpoints']] = conversion['SST_C']\n",
    "\n",
    "df_subset['Tcl_C'] =np.array(np.nan, '<f8')\n",
    "df_subset['Tcl_C'][conversion['goodpoints']] = conversion['Tcl_C']\n",
    "\n",
    "df_subset['fCO2_SST'] =np.array(np.nan, '<f8')\n",
    "df_subset['fCO2_SST'][conversion['goodpoints']] = conversion['fCO2_SST']\n",
    "\n",
    "df_subset['fCO2_Tym'] =np.array(np.nan, '<f8')\n",
    "df_subset['fCO2_Tym'][conversion['goodpoints']] = conversion['fCO2_Tym']\n",
    "\n",
    "df_subset['pCO2_SST'] =np.array(np.nan, '<f8')\n",
    "df_subset['pCO2_SST'][conversion['goodpoints']] = conversion['pCO2_SST']\n",
    "\n",
    "df_subset['pCO2_Tym'] =np.array(np.nan, '<f8')\n",
    "df_subset['pCO2_Tym'][conversion['goodpoints']] = conversion['pCO2_Tym']\n",
    "\n",
    "df_subset['qf'] =np.array(np.nan, '<f8')\n",
    "df_subset['qf'][conversion['goodpoints']] = conversion['qf']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write reanalysis output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\SOCATv2\"))\n",
    " df_subset.to_csv('reanalysis_out_31012020.tsv',sep = '\\t',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FluxEngine output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the working directory to the FluxEngine directory\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\"))\n",
    "os.getcwd()\n",
    "import argparse; #parsing command line arguments\n",
    "import inspect; #stack\n",
    "import fluxengine_src.fe_setup_tools_edit as setup;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing on 'DOM-IMA-FLNMYM2' at 31/01/2020 18:09:23\n",
      "Parsing settings file at: fluxengine_src\\settings.xml\n",
      "Converting pressure from Pa to mbar\n",
      "Converting sstfnd from celsius to kelvin.\n",
      "(ofluxghg_flux_calc, FluxEngine._run_fluxengine_) Using the saline skin model (0.100000 psu added to skin salinities)\n",
      "(ofluxghg_flux_calc, FluxEngine._run_fluxengine_) Using SSTfnd data selection with correction for skin temperature (SSTskin = SSTfnd - 0)(ignoring SSTskin data in configuration file).\n",
      "(ofluxghg_flux_calc, FluxEngine._run_fluxengine_) Using the RAPID model (from Woolf et al., 2016)\n",
      "(rate_parameterisation.py: k_Wanninkhof2014.__call__) Using the Wanninkhof 2014 k parameterisation\n",
      "(ofluxghg_flux_calc, FluxEngine._run_fluxengine_) SUCCESS writing file C:\\Users\\kabaldry\\Documents\\FluxEngine-master\\output\\socatv2\\FE_output_31012020.tsv\n",
      "Flux engine exited with exit code: 0\n",
      "completed successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "returnCode, fe = setup.run_fluxengine(reanalysis_out = conversion,configFilePath = 'SOCATv2\\socatv2_30012020.conf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kabaldry\\AppData\\Local\\Continuum\\anaconda3\\envs\\IOCCPEngineFlux\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\output\\socatv2\"))\n",
    "output_file = 'FE_output_31012020.tsv'\n",
    "out = pd.read_table(output_file, sep=\"\\t\")\n",
    "for x in out.columns:\n",
    "    df_subset[x] = out[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(\"C:\\\\Users\\kabaldry\\Documents\\FluxEngine-master\\SOCATv2\"))\n",
    "df_subset.to_csv('FluxEngine_out_30012020.tsv',sep = '\\t',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.data[\"scskin\"].fdata = schmidt_Wanninkhof2014(self.data[\"sstskinC\"].fdata, nx, ny, runParams.GAS)\n",
    "\n",
    "#based on Schmid relationship from Wanninkhof2014 - Relationship between wind speed and gas exchange over the ocean revisited, Limnology and Oceanography\n",
    "def schmidt_Wanninkhof2014(sstC_fdata, nx, ny, gas):\n",
    "    sc_fdata = array([missing_value] * nx*ny)\n",
    "\n",
    "    if 'co2' in gas.lower():\n",
    "        for i in arange(nx * ny):\n",
    "            if (sstC_fdata[i] != missing_value):\n",
    "                # relationship is only valid for temperatures <=30.0 oC\n",
    "                sc_fdata[i] = 2116.8 + (-136.25 * sstC_fdata[i]) + (4.7353 * sstC_fdata[i]**2) + (-0.092307 * sstC_fdata[i]**3) + (0.0007555 * sstC_fdata[i]**4);\n",
    "            else:\n",
    "            # assigning invalid values\n",
    "                sc_fdata[i] = missing_value\n",
    "    return sc_fdata\n",
    "\n",
    "\n",
    "class k_Wanninkhof2014(KCalculationBase):\n",
    "    #def __init__(self, kb_weighting, kd_weighting):\n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__;\n",
    "    \n",
    "    def input_names(self):\n",
    "        return [\"windu10\", \"windu10_moment2\", \"scskin\"];\n",
    "    \n",
    "    def output_names(self):\n",
    "        return [\"k\"];\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        # using OceanFlux GHG kt approach with kd based on Wanninkhof2014\n",
    "        # Wanninkhof, Rik. \"Relationship between wind speed and gas exchange over the ocean revisited.\" Limnology and Oceanography: Methods 12.6 (2014): 351-362.\n",
    "        function = \"(rate_parameterisation.py: k_Wanninkhof2014.__call__)\";\n",
    "        print \"%s Using the Wanninkhof 2014 k parameterisation\" % (function);\n",
    "        \n",
    "        try:\n",
    "            #for ease of access, simply assign attributes to each input/output.\n",
    "            for name in self.input_names() + self.output_names():\n",
    "                setattr(self, name, data[name].fdata);\n",
    "            data[\"k\"].standardName=\"W14\" \n",
    "            data[\"k\"].longName=\"Wanninkhof 2014, Limnol. Oceanogr.: Methods 12, 2014, 351-362\"#IGA\n",
    "        except KeyError as e:\n",
    "           print \"%s: Required data layer for selected k parameterisation was not found.\" % function;\n",
    "           print type(e), e.args;\n",
    "           return False;\n",
    "        \n",
    "        #determine the k relationship\n",
    "        for i in arange(len(self.k)):   \n",
    "            self.k[i] = DataLayer.missing_value\n",
    "            #if ( (self.windu10[i] != DataLayer.missing_value) and (self.windu10_moment2[i] != DataLayer.missing_value) and (self.windu10_moment3[i] != DataLayer.missing_value) and (self.scskin[i] != DataLayer.missing_value) and (self.scskin[i] > 0.0) ):\n",
    "            if ( (self.windu10[i] != DataLayer.missing_value) and (self.windu10_moment2[i] != DataLayer.missing_value) and (self.scskin[i] != DataLayer.missing_value) and (self.scskin[i] > 0.0) ):#SOCATv4 - no need for wind moment 3\n",
    "               self.k[i] = 0.251 * self.windu10_moment2[i]\n",
    "               self.k[i] = self.k[i] * sqrt(660.0/self.scskin[i])\n",
    "               \n",
    "               #self.k[i] = self.k[i]# /36.0 # conversion from cm/h to 10^-4 m/s (100/3600) = 1/36\n",
    "            else:\n",
    "               self.k[i] = DataLayer.missing_value\n",
    "        return True;\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
